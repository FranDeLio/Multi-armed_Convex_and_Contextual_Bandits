# multi-armed-bandits-and-convexity
A repository to house and document code and results derived from exploration of black-box optimization via multi-armed bandit methods and stochastic approximation techniques. Contextual techniques will be explored for both families of methods, with an emphasis on exploitation of convexity and concavity in the rewards' structure.
